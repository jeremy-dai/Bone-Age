{"cells":[{"metadata":{"_cell_guid":"c67e806c-e0e6-415b-8cf0-ed92eba5ed37","_uuid":"34b6997bb115a11f47a7f54ce9d9052791b2e707"},"cell_type":"markdown","source":"# Overview\nThis is just a simple first attempt at a model using RestNet50 as a basis and attempting to do regression directly on the age variable using low-resolution images.\n\nThis attemp is based on one of [Kevin Mader's kernals](https://www.kaggle.com/kmader/mobilenet-for-bone-age) and only for practice purpose."},{"metadata":{"_cell_guid":"c3cc4285-bfa4-4612-ac5f-13d10678c09a","_uuid":"725d378daf5f836d4885d67240fc7955f113309d","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # showing and rendering figures\n# io related\nfrom skimage.io import imread\nimport os\nfrom glob import glob\n# not needed in Kaggle, but required in Jupyter\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4b38df6-ffa1-4847-b605-511e72b68231","_uuid":"346da81db6ee7a34af8da8af245b42e681f2ba48","trusted":true},"cell_type":"code","source":"base_bone_dir = os.path.join('..', 'input', 'rsna-bone-age')\nage_df = pd.read_csv(os.path.join(base_bone_dir, 'boneage-training-dataset.csv'))\nage_df['path'] = age_df['id'].map(lambda x: os.path.join(base_bone_dir,\n                                                         'boneage-training-dataset', \n                                                         'boneage-training-dataset', \n                                                         '{}.png'.format(x)))\nage_df['exists'] = age_df['path'].map(os.path.exists)\nprint(age_df['exists'].sum(), 'images found of', age_df.shape[0], 'total')\nage_df['gender'] = age_df['male'].map(lambda x: 'male' if x else 'female')\nboneage_mean = age_df['boneage'].mean()\nboneage_div = 2*age_df['boneage'].std()\n# we don't want normalization for now\nboneage_mean = 0\nboneage_div = 1.0\nage_df['boneage_zscore'] = age_df['boneage'].map(lambda x: (x-boneage_mean)/boneage_div)\nprint(\"missing values:\\n\",(age_df==np.nan).sum())\nage_df.dropna(inplace = True)\nage_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"818da6ca-bbff-4ca0-ad57-ef3a145ae863","_uuid":"688e4340238e013b8459b6f6470993c7de492d83"},"cell_type":"markdown","source":"# Examine the distribution of age and gender"},{"metadata":{"_cell_guid":"5c8bd288-8261-4cbe-a954-e62ac795cc3e","_uuid":"60a8111c4093ca6f69d27a4499442ba7dd750839","trusted":true},"cell_type":"code","source":"#age_df[['boneage', 'boneage_zscore']].hist(figsize = (10, 5))\nage_df['boneage_category'] = pd.cut(age_df['boneage'], 10)\n#age_df['gender'].value_counts().plot(kind=\"bar\")\nimport seaborn as sns\nsns.boxplot('gender', 'boneage',data = age_df)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0ba697ed-85bb-4e9a-9765-4c367db078d1","_uuid":"4df45776bae0b8a1bf9d3eb4eaaebce6e24d726d"},"cell_type":"markdown","source":"# Split Data into Training and Validation"},{"metadata":{"_cell_guid":"1192c6b3-a940-4fa0-a498-d7e0d400a796","_uuid":"a48b300ca4d37a6e8b39f82e3c172739635e4baa","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(age_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = age_df['boneage_category'])\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9954bfda-29bd-4c4d-b526-0a972b3e43e2","_uuid":"9529ab766763a9f122786464c24ab1ebe22c6006","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.resnet50 import preprocess_input\nIMG_SIZE = (224, 224) # slightly smaller than restnet50 normally expects\ncore_idg = ImageDataGenerator(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range = 0.15, \n                              width_shift_range = 0.15, \n                              rotation_range = 5, \n                              shear_range = 0.01,\n                              fill_mode = 'nearest',\n                              zoom_range=0.15)\n                            # preprocessing_function = preprocess_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2b377326d381ae8bb50b011add3feb6876ebd1b"},"cell_type":"code","source":"print(train_df['path'].values[0])\nos.path.dirname(train_df['path'].values[0])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b5767f42-da63-4737-8f50-749c1a25aa84","_uuid":"07851e798db3d89ba13db7d4b56ab2b759221464","trusted":true},"cell_type":"code","source":"def from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"810bd229-fec9-43c4-b3bd-afd62e3e9552","_uuid":"1848f5048a9e00668c3778a85deea97f980e4f1c","trusted":true},"cell_type":"code","source":"train_gen = from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'boneage_zscore', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 64)\n\nvalid_gen = from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'boneage_zscore', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 64) # we can use much larger batches for evaluation\n\n#test_X, test_Y = next(valid_gen)\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'boneage_zscore', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 1024)) # one big batch\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2d62234f-aeb0-4eba-8a38-d713d819abf6","_uuid":"8190b4ad60d49fa65af074dd138a19cb8787e983","trusted":true},"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -127, vmax = 127)\n    c_ax.set_title('%2.0f months' % (c_y*boneage_div+boneage_mean))\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"da22790a-672c-474e-b118-9eef15b53160","_uuid":"55d665e1e8a8d83b9db005a66a965f8a90c62da1"},"cell_type":"markdown","source":"# ResNet50 Model"},{"metadata":{"trusted":true,"_uuid":"c3db7a25c2e2a6355d922e8e3bf2d12486b71370"},"cell_type":"code","source":"from keras.metrics import mean_absolute_error\ndef mae_months(in_gt, in_pred):\n    return mean_absolute_error(boneage_div*in_gt, boneage_div*in_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f785ba2573370700a0c840f09443eea3f550510","scrolled":true},"cell_type":"code","source":"from keras.applications import ResNet50\nfrom keras.models import Sequential\nfrom keras.layers import MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization\n\nresnet_weights_path = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nbone_age = Sequential()\nbone_age.add(ResNet50(input_shape =  t_x.shape[1:], include_top=False, pooling='max', weights= resnet_weights_path)) \nbone_age.add(Dense(1, activation = 'linear' ))\n# bone_age.layers[0].trainable = False\n\nbone_age.compile(optimizer = 'adam', loss = 'mse', metrics = [mae_months])\nbone_age.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a956650dae8bad72a0da805c70c365663863f316"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('bone_age')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a9fc2fc05ba6f0f31c54d7d206b83ae1381eb2"},"cell_type":"code","source":"train_gen.batch_size = 16\nbone_age.fit_generator(train_gen, \n                       epochs = 10,\n                       validation_data = (test_X, test_Y),\n                       steps_per_epoch= 3,\n                       validation_steps=1,\n                       callbacks = callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd15c2d6689d861de4f9933d2fd5e8428b57f049"},"cell_type":"code","source":"# load the best version of the model\nbone_age_model.load_weights(weight_path)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"340eef36-f5b2-4b15-a59f-440061a427eb","_uuid":"00850972ae4298f49ed1838b3fc49c2d8fb07547","trusted":true},"cell_type":"code","source":"import keras.backend as K\nrand_idx = np.random.choice(range(len(test_X)), size = 6)\nattn_func = K.function(inputs = [bone_age_model.get_input_at(0), K.learning_phase()],\n           outputs = [attn_layer.get_output_at(0)]\n          )\nfig, m_axs = plt.subplots(len(rand_idx), 2, figsize = (8, 4*len(rand_idx)))\n[c_ax.axis('off') for c_ax in m_axs.flatten()]\nfor c_idx, (img_ax, attn_ax) in zip(rand_idx, m_axs):\n    cur_img = test_X[c_idx:(c_idx+1)]\n    attn_img = attn_func([cur_img, 0])[0]\n    img_ax.imshow(cur_img[0,:,:,0], cmap = 'bone')\n    attn_ax.imshow(attn_img[0, :, :, 0], cmap = 'viridis', \n                   vmin = 0, vmax = 1, \n                   interpolation = 'lanczos')\n    real_age = boneage_div*test_Y[c_idx]+boneage_mean\n    img_ax.set_title('Hand Image\\nAge:%2.2fY' % (real_age/12))\n    pred_age = boneage_div*bone_age_model.predict(cur_img)+boneage_mean\n    attn_ax.set_title('Attention Map\\nPred:%2.2fY' % (pred_age/12))\nfig.savefig('attention_map.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"24796de7-b1e9-4b3b-bcc6-d997aa3e6d16","_uuid":"244bac80d1ea2074e47932e367996e32cbab6a3d"},"cell_type":"markdown","source":"# Evaluate the results\nHere we evaluate the results by loading the best version of the model and seeing how the predictions look on the results. We then visualize spec"},{"metadata":{"_cell_guid":"d0edaf00-4b7c-4f65-af0b-e5a03b9b8428","_uuid":"b421b6183b1919a7414482f0b1ac611079e45174","trusted":true},"cell_type":"code","source":"pred_Y = boneage_div*bone_age.predict(test_X, batch_size = 32, verbose = True)+boneage_mean\ntest_Y_months = boneage_div*test_Y+boneage_mean","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"15189df2-3fed-495e-9661-97bb2b712dfd","_uuid":"10162e055ca7cd52878a289bab377231787ab732","trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(1,1, figsize = (6,6))\nax1.plot(test_Y_months, pred_Y, 'r.', label = 'predictions')\nax1.plot(test_Y_months, test_Y_months, 'b-', label = 'actual')\nax1.legend()\nax1.set_xlabel('Actual Age (Months)')\nax1.set_ylabel('Predicted Age (Months)')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c34f049f-b032-45bf-9d5e-a756ecc46a82","_uuid":"ba87d0e7c3a77181487b99ca64d13de2aa8a21ee","trusted":true},"cell_type":"code","source":"ord_idx = np.argsort(test_Y)\nord_idx = ord_idx[np.linspace(0, len(ord_idx)-1, 8).astype(int)] # take 8 evenly spaced ones\nfig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\nfor (idx, c_ax) in zip(ord_idx, m_axs.flatten()):\n    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n    \n    c_ax.set_title('Age: %2.1fY\\nPredicted Age: %2.1fY' % (test_Y_months[idx]/12.0, \n                                                           pred_Y[idx]/12.0))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cfd5c357-83fa-42ef-85d7-1d8667bbdb34","_uuid":"87fd08f683ddececdbe634a0fc4291d02d06b958","trusted":true},"cell_type":"code","source":"!rm -rf ~/.keras","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}